{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Regression\n",
    "\n",
    "Last week we introduced the basics of how to do simple linear regression in Python. However, that's obviously not the standard way we do analysis in economics. We need to dig a little deeper.\n",
    "\n",
    "First, we'll start off by adding more variables to our regression, including how to use dummy variables. \n",
    "\n",
    "Then, we'll look at endogeneity and how to implement IV regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the same packages we used last week:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm # This is where we will get OLS\n",
    "from statsmodels.iolib.summary2 import summary_col # This is a handy way to look at model results side-by-side\n",
    "\n",
    "# For IV, we will need to pull from another package that is not included in Anaconda, so we need to install it:\n",
    "# !pip install linearmodels\n",
    "from linearmodels.iv import IV2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Regression\n",
    "\n",
    "We'll continue with the same data we were looking at in last week's notes. If you don't know what I'm talking about look at those. The authors of that paper had some extended models in their Table 2, so we can try to replicate those. Therefore, we'll need the Table 2 data. It's on [GitHub](https://github.com/UC-Davis-ARE-Econ/Python_Boot_Camp/blob/master/Data/maketable2.dta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from that dumb Stata .dta file:\n",
    "df2 = pd.read_stata('https://github.com/UC-Davis-ARE-Econ/Python_Boot_Camp/raw/master/Data/maketable2.dta')\n",
    "\n",
    "# Add a constant term (See Week 3 notes if you don't know why):\n",
    "df2['constant'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we have to put together the collections of $X$ variables we want to use as our explanatory variables. As we talked about last week, you have to be rather specific with Python and tell it which variables you want to use at any given time. So when you run a regression using the `OLS` function from `statsmodels` you will specify the variables to use.\n",
    "\n",
    "There are two ways to do this. First, we can create a new object for each of the collections of $X$ variables. That is, we can create a new dataframe that is a subset of the original dataframe for each set of variables we want to use. We do that by indexing:\n",
    "\n",
    "    X1 = df2['constant', 'avexpr']\n",
    "    X2 = df2['constant', 'avexpr', 'lat_abst']\n",
    "    X3 = df2['constant', 'avexpr', 'lat_abst', 'asia', 'africa', 'other']\n",
    "   \n",
    "Pretty simple, and not dissimilar from things we have done before. However, each of these new dataframes is created in memory, so if you are dealing with a big dataset you may have just eaten up a lot of your available RAM. That's because we are essentially copying the data that are held in memory already in `df2`. \n",
    "\n",
    "There's another way to do this that avoids creating copies of the dataframe. In this case we will just create lists that contain the indexes we want to call. Then, we can use the list as the index for `df2` when we actually need to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = ['constant', 'avexpr']\n",
    "X2 = ['constant', 'avexpr', 'lat_abst']\n",
    "X3 = ['constant', 'avexpr', 'lat_abst', 'asia', 'africa', 'other']\n",
    "y = ['logpgp95']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit our three models using the `OLS` function and the `.fit()` method. Note that I am also making sure to specify that we want robust standard errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = sm.OLS(df2['logpgp95'], df2[X1], missing = 'drop').fit(cov_type = 'HC0')\n",
    "reg2 = sm.OLS(df2['logpgp95'], df2[X2], missing = 'drop').fit(cov_type = 'HC0')\n",
    "reg3 = sm.OLS(df2['logpgp95'], df2[X3], missing = 'drop').fit(cov_type = 'HC0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, Python doesn't show us these results automatically. We could use the `.summary()` method on the fitted regression objects like we did last week, but that would also only show us results one at a time.\n",
    "\n",
    "Instead, we can use another function from `statsmodels` called `summary_col`, which will show us the results of the three models side-by-side. There are a couple things we need to do to set this up, but it should be a good way to view the results.\n",
    "\n",
    "First, we need to use a dictionary to indicate which additional data points we want to include. Let's say we also want to see $R^2$ and the number of observations. We create a dictionary object that will pull these data points from the regression objects when `summary_col` needs them. Note the use of the anonymous functions with the `lambda` in the code. This is so that we do not have to write a new function just to pull these values, and Python will do it automatically when reading the dictionary. \n",
    "\n",
    "The `summary_col` function also gives us several options to choose from. `float_format` will let us choose the number of decimal places to round to, `model_names` lets us give names to each column, and `regressor_order` allows us to specify where to display the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Table 2 - OLS Regressions\n",
      "=========================================\n",
      "                 Model 1 Model 2 Model 3 \n",
      "-----------------------------------------\n",
      "constant         4.63*** 4.87*** 5.85*** \n",
      "                 (0.24)  (0.28)  (0.29)  \n",
      "avexpr           0.53*** 0.46*** 0.39*** \n",
      "                 (0.03)  (0.05)  (0.05)  \n",
      "lat_abst                 0.87*   0.33    \n",
      "                         (0.49)  (0.43)  \n",
      "asia                             -0.15   \n",
      "                                 (0.18)  \n",
      "africa                           -0.92***\n",
      "                                 (0.15)  \n",
      "other                            0.30*   \n",
      "                                 (0.17)  \n",
      "R-squared        0.61    0.62    0.72    \n",
      "No. observations 111     111     111     \n",
      "=========================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "# Set up dictionary to specify additional values to include:\n",
    "info_dict = {'R-squared' : lambda x: f\"{x.rsquared:.2f}\",\n",
    "           'No. observations' : lambda x: f\"{int(x.nobs):d}\"}\n",
    "\n",
    "# Construct the table object with the options we want:\n",
    "results_table = summary_col(results=[reg1,reg2,reg3],\n",
    "                            float_format='%0.2f',\n",
    "                            stars = True,\n",
    "                            model_names=['Model 1',\n",
    "                                         'Model 2',\n",
    "                                         'Model 3'],\n",
    "                            info_dict=info_dict,\n",
    "                            regressor_order=['constant',\n",
    "                                             'avexpr',\n",
    "                                             'lat_abst',\n",
    "                                             'asia',\n",
    "                                             'africa'])\n",
    "\n",
    "# Add a title so it looks nice:\n",
    "results_table.add_title('Table 2 - OLS Regressions')\n",
    "\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, it even has stars for significant coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "\n",
    "We've actually already run a regression with a couple of dummy variables. Note that `asia`, `africa`, and `other` are dummy variables, simply indicating where the country is located. So, we can see that there is no need to treat them any differently than other variables when working with these regression functions.\n",
    "\n",
    "There is one more thing worth noting about dummy variables. The `statsmodels` package actually includes are very useful function for creating dummy variables from a single category variable. Suppose that instead of having several dummy variables already, we just have one variable with values of `asia`, `africa`, and `other`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>africa</th>\n",
       "      <th>asia</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>africa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>africa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>africa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>africa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>africa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>other</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location africa asia other\n",
       "0   africa    1.0  0.0   0.0\n",
       "1    other    0.0  0.0   1.0\n",
       "2     asia    0.0  1.0   0.0\n",
       "3     asia    0.0  1.0   0.0\n",
       "4   africa    1.0  0.0   0.0\n",
       "5   africa    1.0  0.0   0.0\n",
       "6   africa    1.0  0.0   0.0\n",
       "7   africa    1.0  0.0   0.0\n",
       "8    other    0.0  0.0   1.0\n",
       "9     asia    0.0  1.0   0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some fake data:\n",
    "np.random.seed(582)\n",
    "fake_category = np.random.choice(['asia', 'africa', 'other'], 10)\n",
    "\n",
    "# Generate dummy variables from this list: \n",
    "dummies = sm.categorical(fake_category)\n",
    "\n",
    "pd.DataFrame(dummies, columns = ['location', 'africa', 'asia', 'other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endogeneity\n",
    "\n",
    "We know that there are lots of cases where endogeneity is an issue. In fact, this paper we are replicating specifically refers to an endogenous relationship between the economic outcome, GDP, and the strength of institutions. It's definitely a case of chicken-and-egg, so we should be worried about the relationship between `logpgp95` and `avexpr`.\n",
    "\n",
    "We'll explore how to do this two ways: first we'll go through the two stages of two-stage least squares, then we'll use the command included in `statsmodels`. \n",
    "\n",
    "The paper we are replicating uses mortality rates as an instrument for institutional differences in the protection against appropriation. I don't know how realistic that it, but they do demonstrate that there is a relationship between these two variables, so there it is at least a valid instrument. \n",
    "\n",
    "Let's jump in to the first stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
